# Differential privacy research

---

## What is it?

Differential privacy is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset while withholding information about individuals in the dataset. The idea behind differential privacy is that if the effect of making an arbitrary single substitution in the database is small enough, the query result cannot be used to infer much about any single individual, and therefore provides privacy. 

This research takes a look at the two main models of differential privacy: ε-differential privacy and (ε, δ) -
differential privacy. 


## Table of Contents

**1) DP_research.pdf**: review article describes accuracy results depending on variable parameters in differential privacy in classical and deep learning models


**2) dp_in_deep_learning.ipynb**: Jupyter Notebook with deep leaning models and final accuracy results


**3) classic_methods.ipynb**: Jupyter Notebook with classical linear models and final accuracy results


## How to start

**1) dp_in_deep_learning.ipynb**: Get results using deep leaning models

**2) classic_methods.ipynb**:  Get results using linear models
